NAME: local-confluent-kafka
LAST DEPLOYED: Fri Feb 16 09:07:33 2024
NAMESPACE: default
STATUS: pending-install
REVISION: 1
USER-SUPPLIED VALUES:
{}

COMPUTED VALUES:
cp-control-center:
  enabled: false
  heapOptions: -Xms512M -Xmx512M
  image: confluentinc/cp-enterprise-control-center
  imagePullSecrets: null
  imageTag: 6.1.0
  resources: {}
cp-kafka:
  affinity: {}
  brokers: 3
  configurationOverrides:
    listener.security.protocol.map: PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
    offsets.topic.replication.factor: "3"
  cp-zookeeper:
    enabled: true
    persistence:
      dataDirSize: 5Gi
      dataLogDirSize: 5Gi
      enabled: true
    servers: 3
    url: ""
  customEnv: {}
  enabled: true
  global: {}
  heapOptions: -Xms512M -Xmx512M
  image: confluentinc/cp-enterprise-kafka
  imagePullPolicy: IfNotPresent
  imageTag: 6.1.0
  jmx:
    port: 5555
  nodeSelector: {}
  nodeport:
    enabled: false
    firstListenerPort: 31090
    servicePort: 19092
  persistence:
    disksPerBroker: 1
    enabled: true
    size: 5Gi
  podAnnotations: {}
  podManagementPolicy: OrderedReady
  prometheus:
    jmx:
      enabled: true
      image: solsson/kafka-prometheus-jmx-exporter@sha256
      imagePullPolicy: IfNotPresent
      imageTag: 6f82e2b0464f50da8104acd7363fb9b995001ddff77d248379f8788e78946143
      port: 5556
      resources: {}
  resources: {}
  securityContext:
    runAsUser: 0
  tolerations: []
  updateStrategy: RollingUpdate
cp-kafka-connect:
  affinity: {}
  configurationOverrides:
    config.storage.replication.factor: "3"
    internal.key.converter: org.apache.kafka.connect.json.JsonConverter
    internal.value.converter: org.apache.kafka.connect.json.JsonConverter
    key.converter: io.confluent.connect.avro.AvroConverter
    key.converter.schemas.enable: "false"
    offset.storage.replication.factor: "3"
    plugin.path: /usr/share/java,/usr/share/confluent-hub-components
    status.storage.replication.factor: "3"
    value.converter: io.confluent.connect.avro.AvroConverter
    value.converter.schemas.enable: "false"
  cp-schema-registry:
    url: ""
  customEnv: {}
  enabled: true
  global: {}
  heapOptions: -Xms512M -Xmx512M
  image: confluentinc/cp-kafka-connect
  imagePullPolicy: IfNotPresent
  imageTag: 6.1.0
  jmx:
    port: 5555
  kafka:
    bootstrapServers: ""
  nodeSelector: {}
  podAnnotations: {}
  prometheus:
    jmx:
      enabled: true
      image: solsson/kafka-prometheus-jmx-exporter@sha256
      imagePullPolicy: IfNotPresent
      imageTag: 6f82e2b0464f50da8104acd7363fb9b995001ddff77d248379f8788e78946143
      port: 5556
      resources: {}
  replicaCount: 1
  resources: {}
  servicePort: 8083
  tolerations: []
cp-kafka-rest:
  affinity: {}
  cp-kafka:
    bootstrapServers: ""
  cp-schema-registry:
    url: ""
  cp-zookeeper:
    url: ""
  customEnv: {}
  enabled: true
  external:
    enabled: false
    externalTrafficPolicy: Cluster
    port: 8082
    type: LoadBalancer
  global: {}
  heapOptions: -Xms512M -Xmx512M
  image: confluentinc/cp-kafka-rest
  imagePullPolicy: IfNotPresent
  imageTag: 6.1.0
  jmx:
    port: 5555
  nodeSelector: {}
  podAnnotations: {}
  prometheus:
    jmx:
      enabled: true
      image: solsson/kafka-prometheus-jmx-exporter@sha256
      imagePullPolicy: IfNotPresent
      imageTag: 6f82e2b0464f50da8104acd7363fb9b995001ddff77d248379f8788e78946143
      port: 5556
      resources: {}
  replicaCount: 1
  resources: {}
  servicePort: 8082
  tolerations: []
cp-ksql-server:
  affinity: {}
  configurationOverrides: {}
  cp-schema-registry:
    url: ""
  enabled: true
  external:
    enabled: false
    externalTrafficPolicy: Cluster
    port: 8088
    type: LoadBalancer
  global: {}
  heapOptions: -Xms512M -Xmx512M
  image: confluentinc/cp-ksqldb-server
  imagePullPolicy: IfNotPresent
  imageTag: 6.1.0
  jmx:
    port: 5555
  kafka:
    bootstrapServers: ""
  ksql:
    headless: false
  nodeSelector: {}
  podAnnotations: {}
  prometheus:
    jmx:
      enabled: true
      image: solsson/kafka-prometheus-jmx-exporter@sha256
      imagePullPolicy: IfNotPresent
      imageTag: 6f82e2b0464f50da8104acd7363fb9b995001ddff77d248379f8788e78946143
      port: 5556
      resources: {}
  replicaCount: 1
  resources: {}
  servicePort: 8088
  tolerations: []
cp-schema-registry:
  affinity: {}
  configurationOverrides: {}
  customEnv: {}
  enabled: true
  global: {}
  heapOptions: -Xms512M -Xmx512M
  image: confluentinc/cp-schema-registry
  imagePullPolicy: IfNotPresent
  imageTag: 6.1.0
  jmx:
    port: 5555
  kafka:
    bootstrapServers: ""
  nodeSelector: {}
  podAnnotations: {}
  prometheus:
    jmx:
      enabled: true
      image: solsson/kafka-prometheus-jmx-exporter@sha256
      imagePullPolicy: IfNotPresent
      imageTag: 6f82e2b0464f50da8104acd7363fb9b995001ddff77d248379f8788e78946143
      port: 5556
      resources: {}
  replicaCount: 1
  resources: {}
  securityContext:
    fsGroup: 10001
    runAsGroup: 10001
    runAsNonRoot: true
    runAsUser: 10001
  servicePort: 8081
  tolerations: []
cp-zookeeper:
  affinity: {}
  autoPurgePurgeInterval: 24
  autoPurgeSnapRetainCount: 3
  clientPort: 2181
  enabled: true
  global: {}
  heapOptions: -Xms512M -Xmx512M
  image: confluentinc/cp-zookeeper
  imagePullPolicy: IfNotPresent
  imageTag: 6.1.0
  initLimit: 10
  jmx:
    port: 5555
  leaderElectionPort: 3888
  maxClientCnxns: 60
  nodeSelector: {}
  persistence:
    dataDirSize: 10Gi
    dataLogDirSize: 10Gi
    enabled: true
  podAnnotations: {}
  podManagementPolicy: OrderedReady
  prometheus:
    jmx:
      enabled: true
      image: solsson/kafka-prometheus-jmx-exporter@sha256
      imagePullPolicy: IfNotPresent
      imageTag: 6f82e2b0464f50da8104acd7363fb9b995001ddff77d248379f8788e78946143
      port: 5556
      resources: {}
  resources: {}
  securityContext:
    runAsUser: 0
  serverPort: 2888
  servers: 3
  syncLimit: 5
  tickTime: 2000
  tolerations: []
  updateStrategy: RollingUpdate
kafka-ui:
  affinity: {}
  annotations: {}
  autoscaling:
    enabled: false
    maxReplicas: 100
    minReplicas: 1
    targetCPUUtilizationPercentage: 80
  cp-kafka-connect:
    url: ""
  cp-ksql-server:
    url: ""
  cp-schema-registry:
    url: ""
  cp-zookeeper:
    url: ""
  enabled: true
  env: {}
  envs:
    config: {}
    secret: {}
  existingConfigMap: ""
  existingSecret: ""
  fullnameOverride: ""
  global: {}
  image:
    pullPolicy: IfNotPresent
    registry: docker.io
    repository: provectuslabs/kafka-ui
    tag: v0.7.1
  ingress:
    annotations: {}
    enabled: false
    host: ""
    ingressClassName: ""
    path: /
    pathType: Prefix
    precedingPaths: []
    succeedingPaths: []
    tls:
      enabled: false
      secretName: ""
  initContainers: {}
  kafka:
    bootstrapServers: ""
  nameOverride: ""
  networkPolicy:
    egressRules:
      customRules: []
    enabled: false
    ingressRules:
      customRules: []
  nodeSelector: {}
  podAnnotations: {}
  podLabels: {}
  podSecurityContext: {}
  probes:
    useHttpsScheme: false
  replicaCount: 1
  resources: {}
  securityContext: {}
  service:
    nodePort: 30000
    port: 80
    type: NodePort
  serviceAccount:
    annotations: {}
    create: true
    name: ""
  tolerations: []
  volumeMounts: {}
  volumes: {}
  yamlApplicationConfig: {}
  yamlApplicationConfigConfigMap: {}

HOOKS:
---
# Source: cp-helm-charts/charts/cp-kafka/templates/tests/canary-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "local-confluent-kafka-canary"
  annotations:
    "helm.sh/hook": test-success
    "helm.sh/hook-delete-policy": "before-hook-creation,hook-succeeded"
spec:
  containers:
  - name: local-confluent-kafka-canary
    image: "confluentinc/cp-enterprise-kafka:6.1.0"
    imagePullPolicy: "IfNotPresent"
    command:
    - sh
    - -c
    - |
      # Delete the topic if it exists
      kafka-topics --zookeeper local-confluent-kafka-cp-zookeeper-headless:2181 --topic local-confluent-kafka-cp-kafka-canary-topic --delete --if-exists
      # Create the topic
      kafka-topics --zookeeper local-confluent-kafka-cp-zookeeper-headless:2181 --topic local-confluent-kafka-cp-kafka-canary-topic --create --partitions 1 --replication-factor 1 --if-not-exists && \
      # Create a message
      MESSAGE="`date -u`" && \
      # Produce a test message to the topic
      echo "$MESSAGE" | kafka-console-producer --broker-list local-confluent-kafka-cp-kafka:9092 --topic local-confluent-kafka-cp-kafka-canary-topic && \
      # Consume a test message from the topic
      kafka-console-consumer --bootstrap-server local-confluent-kafka-cp-kafka-headless:9092 --topic local-confluent-kafka-cp-kafka-canary-topic --from-beginning --max-messages 1 --timeout-ms 30000 | grep "$MESSAGE"
  restartPolicy: Never
MANIFEST:
---
# Source: cp-helm-charts/charts/cp-zookeeper/templates/poddisruptionbudget.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: local-confluent-kafka-cp-zookeeper-pdb
  labels:
    app: cp-zookeeper
    chart: cp-zookeeper-0.1.0
    release: local-confluent-kafka
    heritage: Helm
spec:
  selector:
    matchLabels:
      app: cp-zookeeper
      release: local-confluent-kafka
  maxUnavailable: 1
---
# Source: cp-helm-charts/charts/kafka-ui/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: local-confluent-kafka-kafka-ui
  namespace: default
  labels:
    helm.sh/chart: kafka-ui-0.7.5
    app.kubernetes.io/name: kafka-ui
    app.kubernetes.io/instance: local-confluent-kafka
    app.kubernetes.io/version: "v0.7.1"
    app.kubernetes.io/managed-by: Helm
---
# Source: cp-helm-charts/charts/cp-kafka-connect/templates/jmx-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: local-confluent-kafka-cp-kafka-connect-jmx-configmap
  labels:
    app: cp-kafka-connect
    chart: cp-kafka-connect-0.1.0
    release: local-confluent-kafka
    heritage: Helm
data:
  jmx-kafka-connect-prometheus.yml: |+
    jmxUrl: service:jmx:rmi:///jndi/rmi://localhost:5555/jmxrmi
    lowercaseOutputName: true
    lowercaseOutputLabelNames: true
    ssl: false
    whitelistObjectNames:
    - kafka.connect:type=connect-worker-metrics
    - kafka.connect:type=connect-metrics,client-id=*
    - kafka.connect:type=connector-task-metrics,connector=*,task=*
    rules:
    - pattern : "kafka.connect<type=connect-worker-metrics>([^:]+):"
      name: "cp_kafka_connect_connect_worker_metrics_$1"
    - pattern : "kafka.connect<type=connect-metrics, client-id=([^:]+)><>([^:]+)"
      name: "cp_kafka_connect_connect_metrics_$1_$2"
    - pattern : "kafka.connect<type=connector-task-metrics, connector=([^:]+), task=([^:]+)><>status: ([^:]+)"
      name: "cp_kafka_connect_connect_connector_metrics"
      value: 1
      labels:
        connector: $1
        task: $2
        status: $3
---
# Source: cp-helm-charts/charts/cp-kafka-rest/templates/jmx-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: local-confluent-kafka-cp-kafka-rest-jmx-configmap
  labels:
    app: cp-kafka-rest
    chart: cp-kafka-rest-0.1.0
    release: local-confluent-kafka
    heritage: Helm
data:
  jmx-kafka-rest-prometheus.yml: |+
    jmxUrl: service:jmx:rmi:///jndi/rmi://localhost:5555/jmxrmi
    lowercaseOutputName: true
    lowercaseOutputLabelNames: true
    ssl: false
    whitelistObjectNames:
    - kafka.rest:type=jetty-metrics
    - kafka.rest:type=jersey-metrics
    rules:
    - pattern : 'kafka.rest<type=jetty-metrics>([^:]+):'
      name: "cp_kafka_rest_jetty_metrics_$1"
    - pattern : 'kafka.rest<type=jersey-metrics>([^:]+):'
      name: "cp_kafka_rest_jersey_metrics_$1"
---
# Source: cp-helm-charts/charts/cp-kafka/templates/jmx-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: local-confluent-kafka-cp-kafka-jmx-configmap
  labels:
    app: cp-kafka
    chart: cp-kafka-0.1.0
    release: local-confluent-kafka
    heritage: Helm
data:
  jmx-kafka-prometheus.yml: |+
    jmxUrl: service:jmx:rmi:///jndi/rmi://localhost:5555/jmxrmi
    lowercaseOutputName: true
    lowercaseOutputLabelNames: true
    ssl: false
    whitelistObjectNames:
    - kafka.server:type=ReplicaManager,name=*
    - kafka.controller:type=KafkaController,name=*
    - kafka.server:type=BrokerTopicMetrics,name=*
    - kafka.network:type=RequestMetrics,name=RequestsPerSec,request=*
    - kafka.network:type=SocketServer,name=NetworkProcessorAvgIdlePercent
    - kafka.server:type=ReplicaFetcherManager,name=MaxLag,clientId=*
    - kafka.server:type=KafkaRequestHandlerPool,name=RequestHandlerAvgIdlePercent
    - kafka.controller:type=ControllerStats,name=*
    - kafka.server:type=SessionExpireListener,name=*
    rules:
    - pattern : kafka.server<type=ReplicaManager, name=(.+)><>(Value|OneMinuteRate)
      name: "cp_kafka_server_replicamanager_$1"
    - pattern : kafka.controller<type=KafkaController, name=(.+)><>Value
      name: "cp_kafka_controller_kafkacontroller_$1"
    - pattern : kafka.server<type=BrokerTopicMetrics, name=(.+)><>OneMinuteRate
      name: "cp_kafka_server_brokertopicmetrics_$1"
    - pattern : kafka.network<type=RequestMetrics, name=RequestsPerSec, request=(.+)><>OneMinuteRate
      name: "cp_kafka_network_requestmetrics_requestspersec_$1"
    - pattern : kafka.network<type=SocketServer, name=NetworkProcessorAvgIdlePercent><>Value
      name: "cp_kafka_network_socketserver_networkprocessoravgidlepercent"
    - pattern : kafka.server<type=ReplicaFetcherManager, name=MaxLag, clientId=(.+)><>Value
      name: "cp_kafka_server_replicafetchermanager_maxlag_$1"
    - pattern : kafka.server<type=KafkaRequestHandlerPool, name=RequestHandlerAvgIdlePercent><>OneMinuteRate
      name: "cp_kafka_kafkarequesthandlerpool_requesthandleravgidlepercent"
    - pattern : kafka.controller<type=ControllerStats, name=(.+)><>OneMinuteRate
      name: "cp_kafka_controller_controllerstats_$1"
    - pattern : kafka.server<type=SessionExpireListener, name=(.+)><>OneMinuteRate
      name: "cp_kafka_server_sessionexpirelistener_$1"
---
# Source: cp-helm-charts/charts/cp-ksql-server/templates/jmx-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: local-confluent-kafka-cp-ksql-server-jmx-configmap
  labels:
    app: cp-ksql-server
    chart: cp-ksql-server-0.1.0
    release: local-confluent-kafka
    heritage: Helm
data:
  jmx-ksql-server-prometheus.yml: |+
    jmxUrl: service:jmx:rmi:///jndi/rmi://localhost:5555/jmxrmi
    lowercaseOutputName: true
    lowercaseOutputLabelNames: true
    ssl: false
    whitelistObjectNames:
    - io.confluent.ksql.metrics:type=ksql-engine-query-stats
    rules:
    - pattern : 'io.confluent.ksql.metrics<type=ksql-engine-query-stats>([^:]+):'
      name: "cp_ksql_server_metrics_$1"
---
# Source: cp-helm-charts/charts/cp-ksql-server/templates/ksql-queries-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: local-confluent-kafka-cp-ksql-server-ksql-queries-configmap
  labels:
    app: cp-ksql-server
    chart: cp-ksql-server-0.1.0
    release: local-confluent-kafka
    heritage: Helm
data:
  queries.sql: |-
    -- From http://docs.confluent.io/current/ksql/docs/tutorials/basics-docker.html#create-a-stream-and-table
    
    -- Create a stream pageviews_original from the Kafka topic pageviews, specifying the value_format of DELIMITED
    CREATE STREAM pageviews_original (viewtime bigint, userid varchar, pageid varchar) WITH (kafka_topic='pageviews', value_format='DELIMITED');
    
    -- Create a table users_original from the Kafka topic users, specifying the value_format of JSON
    CREATE TABLE users_original (registertime BIGINT, gender VARCHAR, regionid VARCHAR, userid VARCHAR) WITH (kafka_topic='users', value_format='JSON', key = 'userid');
    
    -- Create a persistent query by using the CREATE STREAM keywords to precede the SELECT statement
    CREATE STREAM pageviews_enriched AS SELECT users_original.userid AS userid, pageid, regionid, gender FROM pageviews_original LEFT JOIN users_original ON pageviews_original.userid = users_original.userid;
    
    -- Create a new persistent query where a condition limits the streams content, using WHERE
    CREATE STREAM pageviews_female AS SELECT * FROM pageviews_enriched WHERE gender = 'FEMALE';
    
    -- Create a new persistent query where another condition is met, using LIKE
    CREATE STREAM pageviews_female_like_89 WITH (kafka_topic='pageviews_enriched_r8_r9') AS SELECT * FROM pageviews_female WHERE regionid LIKE '%_8' OR regionid LIKE '%_9';
    
    -- Create a new persistent query that counts the pageviews for each region and gender combination in a tumbling window of 30 seconds when the count is greater than one
    CREATE TABLE pageviews_regions WITH (VALUE_FORMAT='avro') AS SELECT gender, regionid , COUNT(*) AS numusers FROM pageviews_enriched WINDOW TUMBLING (size 30 second) GROUP BY gender, regionid HAVING COUNT(*) > 1;
---
# Source: cp-helm-charts/charts/cp-schema-registry/templates/jmx-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: local-confluent-kafka-cp-schema-registry-jmx-configmap
  labels:
    app: cp-schema-registry
    chart: cp-schema-registry-0.1.0
    release: local-confluent-kafka
    heritage: Helm
data:
  jmx-schema-registry-prometheus.yml: |+
    jmxUrl: service:jmx:rmi:///jndi/rmi://localhost:5555/jmxrmi
    lowercaseOutputName: true
    lowercaseOutputLabelNames: true
    ssl: false
    whitelistObjectNames:
    - kafka.schema.registry:type=jetty-metrics
    - kafka.schema.registry:type=master-slave-role
    - kafka.schema.registry:type=jersey-metrics
    rules:
    - pattern : 'kafka.schema.registry<type=jetty-metrics>([^:]+):'
      name: "cp_kafka_schema_registry_jetty_metrics_$1"
    - pattern : 'kafka.schema.registry<type=master-slave-role>([^:]+):'
      name: "cp_kafka_schema_registry_master_slave_role"
    - pattern : 'kafka.schema.registry<type=jersey-metrics>([^:]+):'
      name: "cp_kafka_schema_registry_jersey_metrics_$1"
---
# Source: cp-helm-charts/charts/cp-zookeeper/templates/jmx-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: local-confluent-kafka-cp-zookeeper-jmx-configmap
  labels:
    app: cp-zookeeper
    chart: cp-zookeeper-0.1.0
    release: local-confluent-kafka
    heritage: Helm
data:
  jmx-zookeeper-prometheus.yml: |+
    jmxUrl: service:jmx:rmi:///jndi/rmi://localhost:5555/jmxrmi
    lowercaseOutputName: true
    lowercaseOutputLabelNames: true
    ssl: false
    whitelistObjectNames:
    - org.apache.ZooKeeperService:name0=ReplicatedServer_id*
    - org.apache.ZooKeeperService:name0=ReplicatedServer_id*,name1=replica.*
    - org.apache.ZooKeeperService:name0=ReplicatedServer_id*,name1=replica.*,name2=*
    - org.apache.ZooKeeperService:name0=ReplicatedServer_id*,name1=replica.*,name2=*,name3=*
    rules:
    - pattern: "org.apache.ZooKeeperService<name0=ReplicatedServer_id(\\d+)><>(\\w+)"
      name: "cp_zookeeper_$2"
    - pattern: "org.apache.ZooKeeperService<name0=ReplicatedServer_id(\\d+), name1=replica.(\\d+)><>(\\w+)"
      name: "cp_zookeeper_$3"
      labels:
        replicaId: "$2"
    - pattern: "org.apache.ZooKeeperService<name0=ReplicatedServer_id(\\d+), name1=replica.(\\d+), name2=(\\w+)><>(\\w+)"
      name: "cp_zookeeper_$4"
      labels:
        replicaId: "$2"
        memberType: "$3"
    - pattern: "org.apache.ZooKeeperService<name0=ReplicatedServer_id(\\d+), name1=replica.(\\d+), name2=(\\w+), name3=(\\w+)><>(\\w+)"
      name: "cp_zookeeper_$4_$5"
      labels:
        replicaId: "$2"
        memberType: "$3"
---
# Source: cp-helm-charts/charts/cp-kafka-connect/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: local-confluent-kafka-cp-kafka-connect
  labels:
    app: cp-kafka-connect
    chart: cp-kafka-connect-0.1.0
    release: local-confluent-kafka
    heritage: Helm
spec:
  ports:
    - name: kafka-connect
      port: 8083
    - name: metrics
      port: 5556
  selector:
    app: cp-kafka-connect
    release: local-confluent-kafka
---
# Source: cp-helm-charts/charts/cp-kafka-rest/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: local-confluent-kafka-cp-kafka-rest
  labels:
    app: cp-kafka-rest
    chart: cp-kafka-rest-0.1.0
    release: local-confluent-kafka
    heritage: Helm
spec:
  ports:
    - name: rest-proxy
      port: 8082
    - name: metrics
      port: 5556
  selector:
    app: cp-kafka-rest
    release: local-confluent-kafka
---
# Source: cp-helm-charts/charts/cp-kafka/templates/headless-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: local-confluent-kafka-cp-kafka-headless
  labels:
    app: cp-kafka
    chart: cp-kafka-0.1.0
    release: local-confluent-kafka
    heritage: Helm
spec:
  ports:
    - port: 9092
      name: broker
  clusterIP: None
  selector:
    app: cp-kafka
    release: local-confluent-kafka
---
# Source: cp-helm-charts/charts/cp-kafka/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: local-confluent-kafka-cp-kafka
  labels:
    app: cp-kafka
    chart: cp-kafka-0.1.0
    release: local-confluent-kafka
    heritage: Helm
spec:
  ports:
    - port: 9092
      name: broker
    - port: 5556
      name: metrics
  selector:
    app: cp-kafka
    release: local-confluent-kafka
---
# Source: cp-helm-charts/charts/cp-ksql-server/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: local-confluent-kafka-cp-ksql-server
  labels:
    app: cp-ksql-server
    chart: cp-ksql-server-0.1.0
    release: local-confluent-kafka
    heritage: Helm
spec:
  ports:
      - name: ksql-server
        port: 8088
      - name: metrics
        port: 5556
  selector:
    app: cp-ksql-server
    release: local-confluent-kafka
---
# Source: cp-helm-charts/charts/cp-schema-registry/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: local-confluent-kafka-cp-schema-registry
  labels:
    app: cp-schema-registry
    chart: cp-schema-registry-0.1.0
    release: local-confluent-kafka
    heritage: Helm
spec:
  ports:
    - name: schema-registry
      port: 8081
    - name: metrics
      port: 5556
  selector:
    app: cp-schema-registry
    release: local-confluent-kafka
---
# Source: cp-helm-charts/charts/cp-zookeeper/templates/headless-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: local-confluent-kafka-cp-zookeeper-headless
  labels:
    app: cp-zookeeper
    chart: cp-zookeeper-0.1.0
    release: local-confluent-kafka
    heritage: Helm
spec:
  ports:
    - port: 2888
      name: server
    - port: 3888
      name: leader-election
  clusterIP: None
  selector:
    app: cp-zookeeper
    release: local-confluent-kafka
---
# Source: cp-helm-charts/charts/cp-zookeeper/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: local-confluent-kafka-cp-zookeeper
  labels:
    app: cp-zookeeper
    chart: cp-zookeeper-0.1.0
    release: local-confluent-kafka
    heritage: Helm
spec:
  type: 
  ports:
    - port: 2181
      name: client
    - name: metrics
      port: 5556
  selector:
    app: cp-zookeeper
    release: local-confluent-kafka
---
# Source: cp-helm-charts/charts/kafka-ui/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: local-confluent-kafka-kafka-ui
  namespace: default
  labels:
    helm.sh/chart: kafka-ui-0.7.5
    app.kubernetes.io/name: kafka-ui
    app.kubernetes.io/instance: local-confluent-kafka
    app.kubernetes.io/version: "v0.7.1"
    app.kubernetes.io/managed-by: Helm
spec:
  type: NodePort
  ports:
    - port: 80
      targetPort: http
      protocol: TCP
      name: http
      nodePort: 30000
  selector:
    app.kubernetes.io/name: kafka-ui
    app.kubernetes.io/instance: local-confluent-kafka
---
# Source: cp-helm-charts/charts/cp-kafka-connect/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: local-confluent-kafka-cp-kafka-connect
  labels:
    app: cp-kafka-connect
    chart: cp-kafka-connect-0.1.0
    release: local-confluent-kafka
    heritage: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cp-kafka-connect
      release: local-confluent-kafka
  template:
    metadata:
      labels:
        app: cp-kafka-connect
        release: local-confluent-kafka
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "5556"
    spec:
      containers:
        - name: prometheus-jmx-exporter
          image: "solsson/kafka-prometheus-jmx-exporter@sha256:6f82e2b0464f50da8104acd7363fb9b995001ddff77d248379f8788e78946143"
          imagePullPolicy: "IfNotPresent"
          command:
          - java
          - -XX:+UnlockExperimentalVMOptions
          - -XX:+UseCGroupMemoryLimitForHeap
          - -XX:MaxRAMFraction=1
          - -XshowSettings:vm
          - -jar
          - jmx_prometheus_httpserver.jar
          - "5556"
          - /etc/jmx-kafka-connect/jmx-kafka-connect-prometheus.yml
          ports:
          - containerPort: 5556
          resources:
            {}
          volumeMounts:
          - name: jmx-config
            mountPath: /etc/jmx-kafka-connect
        - name: cp-kafka-connect-server
          image: "confluentinc/cp-kafka-connect:6.1.0"
          imagePullPolicy: "IfNotPresent"
          ports:
            - name: kafka-connect
              containerPort: 8083
              protocol: TCP
            - containerPort: 5555
              name: jmx
          resources:
            {}
          env:
            - name: CONNECT_REST_ADVERTISED_HOST_NAME
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: CONNECT_BOOTSTRAP_SERVERS
              value: PLAINTEXT://local-confluent-kafka-cp-kafka-headless:9092
            - name: CONNECT_GROUP_ID
              value: local-confluent-kafka
            - name: CONNECT_CONFIG_STORAGE_TOPIC
              value: local-confluent-kafka-cp-kafka-connect-config
            - name: CONNECT_OFFSET_STORAGE_TOPIC
              value: local-confluent-kafka-cp-kafka-connect-offset
            - name: CONNECT_STATUS_STORAGE_TOPIC
              value: local-confluent-kafka-cp-kafka-connect-status
            - name: CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL
              value: http://local-confluent-kafka-cp-schema-registry:8081
            - name: CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL
              value: http://local-confluent-kafka-cp-schema-registry:8081
            - name: KAFKA_HEAP_OPTS
              value: "-Xms512M -Xmx512M"
            - name: "CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR"
              value: "3"
            - name: "CONNECT_INTERNAL_KEY_CONVERTER"
              value: "org.apache.kafka.connect.json.JsonConverter"
            - name: "CONNECT_INTERNAL_VALUE_CONVERTER"
              value: "org.apache.kafka.connect.json.JsonConverter"
            - name: "CONNECT_KEY_CONVERTER"
              value: "io.confluent.connect.avro.AvroConverter"
            - name: "CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE"
              value: "false"
            - name: "CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR"
              value: "3"
            - name: "CONNECT_PLUGIN_PATH"
              value: "/usr/share/java,/usr/share/confluent-hub-components"
            - name: "CONNECT_STATUS_STORAGE_REPLICATION_FACTOR"
              value: "3"
            - name: "CONNECT_VALUE_CONVERTER"
              value: "io.confluent.connect.avro.AvroConverter"
            - name: "CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE"
              value: "false"
            - name: KAFKA_JMX_PORT
              value: "5555"
      volumes:
      - name: jmx-config
        configMap:
          name: local-confluent-kafka-cp-kafka-connect-jmx-configmap
---
# Source: cp-helm-charts/charts/cp-kafka-rest/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: local-confluent-kafka-cp-kafka-rest
  labels:
    app: cp-kafka-rest
    chart: cp-kafka-rest-0.1.0
    release: local-confluent-kafka
    heritage: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cp-kafka-rest
      release: local-confluent-kafka
  template:
    metadata:
      labels:
        app: cp-kafka-rest
        release: local-confluent-kafka
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "5556"
    spec:
      containers:
        - name: prometheus-jmx-exporter
          image: "solsson/kafka-prometheus-jmx-exporter@sha256:6f82e2b0464f50da8104acd7363fb9b995001ddff77d248379f8788e78946143"
          imagePullPolicy: "IfNotPresent"
          command:
          - java
          - -XX:+UnlockExperimentalVMOptions
          - -XX:+UseCGroupMemoryLimitForHeap
          - -XX:MaxRAMFraction=1
          - -XshowSettings:vm
          - -jar
          - jmx_prometheus_httpserver.jar
          - "5556"
          - /etc/jmx-kafka-rest/jmx-kafka-rest-prometheus.yml
          ports:
          - containerPort: 5556
          resources:
            {}
          volumeMounts:
          - name: jmx-config
            mountPath: /etc/jmx-kafka-rest
        - name: cp-kafka-rest-server
          image: "confluentinc/cp-kafka-rest:6.1.0"
          imagePullPolicy: "IfNotPresent"
          ports:
            - name: rest-proxy
              containerPort: 8082
              protocol: TCP
            - containerPort: 5555
              name: jmx
          resources:
            {}
          env:
          - name: KAFKA_REST_HOST_NAME
            valueFrom:
              fieldRef:
                fieldPath: status.podIP
          - name: KAFKA_REST_BOOTSTRAP_SERVERS
            value: PLAINTEXT://local-confluent-kafka-cp-kafka-headless:9092
          - name: KAFKA_REST_SCHEMA_REGISTRY_URL
            value: http://local-confluent-kafka-cp-schema-registry:8081
          - name: KAFKAREST_HEAP_OPTS
            value: "-Xms512M -Xmx512M"
          - name: JMX_PORT
            value: "5555"
      volumes:
      - name: jmx-config
        configMap:
          name: local-confluent-kafka-cp-kafka-rest-jmx-configmap
---
# Source: cp-helm-charts/charts/cp-ksql-server/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: local-confluent-kafka-cp-ksql-server
  labels:
    app: cp-ksql-server
    chart: cp-ksql-server-0.1.0
    release: local-confluent-kafka
    heritage: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cp-ksql-server
      release: local-confluent-kafka
  template:
    metadata:
      labels:
        app: cp-ksql-server
        release: local-confluent-kafka
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "5556"
    spec:
      containers:
        - name: prometheus-jmx-exporter
          image: "solsson/kafka-prometheus-jmx-exporter@sha256:6f82e2b0464f50da8104acd7363fb9b995001ddff77d248379f8788e78946143"
          imagePullPolicy: "IfNotPresent"
          command:
          - java
          - -XX:+UnlockExperimentalVMOptions
          - -XX:+UseCGroupMemoryLimitForHeap
          - -XX:MaxRAMFraction=1
          - -XshowSettings:vm
          - -jar
          - jmx_prometheus_httpserver.jar
          - "5556"
          - /etc/jmx-ksql-server/jmx-ksql-server-prometheus.yml
          ports:
          - containerPort: 5556
          resources:
            {}
          volumeMounts:
          - name: jmx-config
            mountPath: /etc/jmx-ksql-server
        - name: cp-ksql-server
          image: "confluentinc/cp-ksqldb-server:6.1.0"
          imagePullPolicy: "IfNotPresent"
          ports:
            - name: server
              containerPort: 8088
              protocol: TCP
            - containerPort: 5555
              name: jmx
          resources:
            {}
          volumeMounts:
          env:
          - name: KSQL_BOOTSTRAP_SERVERS
            value: PLAINTEXT://local-confluent-kafka-cp-kafka-headless:9092
          - name: KSQL_KSQL_SERVICE_ID
            value: local-confluent-kafka
          - name: KSQL_KSQL_SCHEMA_REGISTRY_URL
            value: http://local-confluent-kafka-cp-schema-registry:8081
          - name: KSQL_HEAP_OPTS
            value: "-Xms512M -Xmx512M"
          - name: KSQL_LISTENERS
            value: http://0.0.0.0:8088
          - name: JMX_PORT
            value: "5555"
      volumes:
      - name: jmx-config
        configMap:
          name: local-confluent-kafka-cp-ksql-server-jmx-configmap
---
# Source: cp-helm-charts/charts/cp-schema-registry/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: local-confluent-kafka-cp-schema-registry
  labels:
    app: cp-schema-registry
    chart: cp-schema-registry-0.1.0
    release: local-confluent-kafka
    heritage: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cp-schema-registry
      release: local-confluent-kafka
  template:
    metadata:
      labels:
        app: cp-schema-registry
        release: local-confluent-kafka
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "5556"
    spec:
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
      containers:
        - name: prometheus-jmx-exporter
          image: "solsson/kafka-prometheus-jmx-exporter@sha256:6f82e2b0464f50da8104acd7363fb9b995001ddff77d248379f8788e78946143"
          imagePullPolicy: "IfNotPresent"
          command:
          - java
          - -XX:+UnlockExperimentalVMOptions
          - -XX:+UseCGroupMemoryLimitForHeap
          - -XX:MaxRAMFraction=1
          - -XshowSettings:vm
          - -jar
          - jmx_prometheus_httpserver.jar
          - "5556"
          - /etc/jmx-schema-registry/jmx-schema-registry-prometheus.yml
          ports:
          - containerPort: 5556
          resources:
            {}
          volumeMounts:
          - name: jmx-config
            mountPath: /etc/jmx-schema-registry
        - name: cp-schema-registry-server
          image: "confluentinc/cp-schema-registry:6.1.0"
          imagePullPolicy: "IfNotPresent"
          ports:
            - name: schema-registry
              containerPort: 8081
              protocol: TCP
            - containerPort: 5555
              name: jmx
          resources:
            {}
          env:
          - name: SCHEMA_REGISTRY_HOST_NAME
            valueFrom:
              fieldRef:
                fieldPath: status.podIP
          - name: SCHEMA_REGISTRY_LISTENERS
            value: http://0.0.0.0:8081
          - name: SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS
            value: PLAINTEXT://local-confluent-kafka-cp-kafka-headless:9092
          - name: SCHEMA_REGISTRY_KAFKASTORE_GROUP_ID
            value: local-confluent-kafka
          - name: SCHEMA_REGISTRY_MASTER_ELIGIBILITY
            value: "true"
          - name: SCHEMA_REGISTRY_HEAP_OPTS
            value: "-Xms512M -Xmx512M"
          
          - name: JMX_PORT
            value: "5555"
      volumes:
      - name: jmx-config
        configMap:
          name: local-confluent-kafka-cp-schema-registry-jmx-configmap
---
# Source: cp-helm-charts/charts/kafka-ui/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: local-confluent-kafka-kafka-ui
  namespace: default
  labels:
    helm.sh/chart: kafka-ui-0.7.5
    app.kubernetes.io/name: kafka-ui
    app.kubernetes.io/instance: local-confluent-kafka
    app.kubernetes.io/version: "v0.7.1"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: kafka-ui
      app.kubernetes.io/instance: local-confluent-kafka
  template:
    metadata:
      annotations:
        checksum/config: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
        checksum/configFromValues: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
        checksum/secret: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
      labels:
        app.kubernetes.io/name: kafka-ui
        app.kubernetes.io/instance: local-confluent-kafka
    spec:
      serviceAccountName: local-confluent-kafka-kafka-ui
      securityContext:
        {}
      containers:
        - name: kafka-ui
          securityContext:
            {}
          image: docker.io/provectuslabs/kafka-ui:v0.7.1
          imagePullPolicy: IfNotPresent
          env:
            - name: KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS
              value: PLAINTEXT://local-confluent-kafka-cp-kafka-headless:9092
            - name: KAFKA_CLUSTERS_0_ZOOKEEPER
              value: 
            - name: KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME
              value: first
            - name: KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS
              value: http://local-confluent-kafka-cp-kafka-connect:8083
            - name: KAFKA_CLUSTERS_0_KSQLDBSERVER
              value: http://local-confluent-kafka-cp-ksql-server:8088
            - name: KAFKA_CLUSTERS_0_SCHEMAREGISTRY
              value: http://local-confluent-kafka-cp-schema-registry:8081
          envFrom:    
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /actuator/health
              port: http
            initialDelaySeconds: 60
            periodSeconds: 30
            timeoutSeconds: 10
          readinessProbe:
            httpGet:
              path: /actuator/health
              port: http
            initialDelaySeconds: 60
            periodSeconds: 30
            timeoutSeconds: 10
          resources:
            {}
---
# Source: cp-helm-charts/charts/cp-kafka/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: local-confluent-kafka-cp-kafka
  labels:
    app: cp-kafka
    chart: cp-kafka-0.1.0
    release: local-confluent-kafka
    heritage: Helm
spec:
  selector:
    matchLabels:
      app: cp-kafka
      release: local-confluent-kafka
  serviceName: local-confluent-kafka-cp-kafka-headless
  podManagementPolicy: OrderedReady
  replicas: 3
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: cp-kafka
        release: local-confluent-kafka
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "5556"
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                  - key: "app"
                    operator: In
                    values:
                    - cp-kafka
                  - key: "release"
                    operator: In
                    values:
                    - local-confluent-kafka
              topologyKey: "kubernetes.io/hostname"
      containers:
      - name: prometheus-jmx-exporter
        image: "solsson/kafka-prometheus-jmx-exporter@sha256:6f82e2b0464f50da8104acd7363fb9b995001ddff77d248379f8788e78946143"
        imagePullPolicy: "IfNotPresent"
        command:
        - java
        - -XX:+UnlockExperimentalVMOptions
        - -XX:+UseCGroupMemoryLimitForHeap
        - -XX:MaxRAMFraction=1
        - -XshowSettings:vm
        - -jar
        - jmx_prometheus_httpserver.jar
        - "5556"
        - /etc/jmx-kafka/jmx-kafka-prometheus.yml
        ports:
        - containerPort: 5556
        resources:
          {}
        volumeMounts:
        - name: jmx-config
          mountPath: /etc/jmx-kafka
      - name: cp-kafka-broker
        image: "confluentinc/cp-enterprise-kafka:6.1.0"
        imagePullPolicy: "IfNotPresent"
        securityContext:
          runAsUser: 0
        ports:
        - containerPort: 9092
          name: kafka
        - containerPort: 5555
          name: jmx
        resources:
          {}
        env:
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: HOST_IP
          valueFrom:
            fieldRef:
              fieldPath: status.hostIP
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: KAFKA_HEAP_OPTS
          value: -Xms512M -Xmx512M
        - name: KAFKA_ZOOKEEPER_CONNECT
          value: "local-confluent-kafka-cp-zookeeper-headless:2181"
        - name: KAFKA_LOG_DIRS
          value: "/opt/kafka/data-0/logs"
        - name: KAFKA_METRIC_REPORTERS
          value: "io.confluent.metrics.reporter.ConfluentMetricsReporter"
        - name: CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS
          value: "PLAINTEXT://local-confluent-kafka-cp-kafka-headless:9092"
        - name: "KAFKA_LISTENER_SECURITY_PROTOCOL_MAP"
          value: "PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT"
        - name: "KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR"
          value: "3"
        - name: KAFKA_JMX_PORT
          value: "5555"
        # This is required because the Downward API does not yet support identification of
        # pod numbering in statefulsets. Thus, we are required to specify a command which
        # allows us to extract the pod ID for usage as the Kafka Broker ID.
        # See: https://github.com/kubernetes/kubernetes/issues/31218
        command:
        - sh
        - -exc
        - |
          export KAFKA_BROKER_ID=${HOSTNAME##*-} && \
          export KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://${POD_NAME}.local-confluent-kafka-cp-kafka-headless.${POD_NAMESPACE}:9092,EXTERNAL://${HOST_IP}:$((31090 + ${KAFKA_BROKER_ID})) && \
          exec /etc/confluent/docker/run
        volumeMounts:
          - name: datadir-0
            mountPath: /opt/kafka/data-0
      volumes:
      - name: jmx-config
        configMap:
          name: local-confluent-kafka-cp-kafka-jmx-configmap
  volumeClaimTemplates:
  - metadata:
      name: datadir-0
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: "5Gi"
---
# Source: cp-helm-charts/charts/cp-zookeeper/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: local-confluent-kafka-cp-zookeeper
  labels:
    app: cp-zookeeper
    chart: cp-zookeeper-0.1.0
    release: local-confluent-kafka
    heritage: Helm
spec:
  selector:
    matchLabels:
      app: cp-zookeeper
      release: local-confluent-kafka
  serviceName: local-confluent-kafka-cp-zookeeper-headless
  podManagementPolicy: OrderedReady
  replicas: 3
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: cp-zookeeper
        release: local-confluent-kafka
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "5556"
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                  - key: "app"
                    operator: In
                    values:
                    - cp-zookeeper
                  - key: "release"
                    operator: In
                    values:
                    - local-confluent-kafka
              topologyKey: "kubernetes.io/hostname"
      containers:
      - name: prometheus-jmx-exporter
        image: "solsson/kafka-prometheus-jmx-exporter@sha256:6f82e2b0464f50da8104acd7363fb9b995001ddff77d248379f8788e78946143"
        imagePullPolicy: "IfNotPresent"
        command:
        - java
        - -XX:+UnlockExperimentalVMOptions
        - -XX:+UseCGroupMemoryLimitForHeap
        - -XX:MaxRAMFraction=1
        - -XshowSettings:vm
        - -jar
        - jmx_prometheus_httpserver.jar
        - "5556"
        - /etc/jmx-zookeeper/jmx-zookeeper-prometheus.yml
        ports:
        - containerPort: 5556
        resources:
          {}
        volumeMounts:
        - name: jmx-config
          mountPath: /etc/jmx-zookeeper
      - name: cp-zookeeper-server
        image: "confluentinc/cp-zookeeper:6.1.0"
        imagePullPolicy: "IfNotPresent"
        securityContext:
          runAsUser: 0
        ports:
        - containerPort: 2181
          name: client
        - containerPort: 2888
          name: server
        - containerPort: 3888
          name: leader-election
        - containerPort: 5555
          name: jmx
        resources:
          {}
        env:
        - name : KAFKA_HEAP_OPTS
          value: "-Xms512M -Xmx512M"
        - name : KAFKA_JMX_PORT
          value: "5555"
        - name : ZOOKEEPER_TICK_TIME
          value: "2000"
        - name : ZOOKEEPER_SYNC_LIMIT
          value: "5"
        - name : ZOOKEEPER_INIT_LIMIT
          value: "10"
        - name : ZOOKEEPER_MAX_CLIENT_CNXNS
          value: "60"
        - name : ZOOKEEPER_AUTOPURGE_SNAP_RETAIN_COUNT
          value: "3"
        - name : ZOOKEEPER_AUTOPURGE_PURGE_INTERVAL
          value: "24"
        - name: ZOOKEEPER_CLIENT_PORT
          value: "2181"
        - name : ZOOKEEPER_SERVERS
          value: "local-confluent-kafka-cp-zookeeper-0.local-confluent-kafka-cp-zookeeper-headless.default:2888:3888;local-confluent-kafka-cp-zookeeper-1.local-confluent-kafka-cp-zookeeper-headless.default:2888:3888;local-confluent-kafka-cp-zookeeper-2.local-confluent-kafka-cp-zookeeper-headless.default:2888:3888"
        # ZOOKEEPER_SERVER_ID is required just to pass cp-zookeeper ensure script for env check,
        # the value(metadata.mame) is not used and will be overwritten in command part
        - name: ZOOKEEPER_SERVER_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        command:
        - "bash"
        - "-c"
        - |
          ZK_FIX_HOST_REGEX="s/${HOSTNAME}\.[^:]*:/0.0.0.0:/g"
          ZOOKEEPER_SERVER_ID=$((${HOSTNAME##*-}+1)) \
          ZOOKEEPER_SERVERS=`echo $ZOOKEEPER_SERVERS | sed -e "$ZK_FIX_HOST_REGEX"` \
          /etc/confluent/docker/run
        volumeMounts:
        - name: datadir
          mountPath: /var/lib/zookeeper/data
        - name: datalogdir
          mountPath: /var/lib/zookeeper/log
      volumes:
      
      - name: jmx-config
        configMap:
          name: local-confluent-kafka-cp-zookeeper-jmx-configmap
  volumeClaimTemplates:
  - metadata:
      name: datadir
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: "10Gi"
  - metadata:
      name: datalogdir
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: "10Gi"

NOTES:
## ------------------------------------------------------
## Zookeeper
## ------------------------------------------------------
Connection string for Confluent Kafka:
  local-confluent-kafka-cp-zookeeper-0.local-confluent-kafka-cp-zookeeper-headless:2181,local-confluent-kafka-cp-zookeeper-1.local-confluent-kafka-cp-zookeeper-headless:2181,...

To connect from a client pod:

1. Deploy a zookeeper client pod with configuration:

    apiVersion: v1
    kind: Pod
    metadata:
      name: zookeeper-client
      namespace: default
    spec:
      containers:
      - name: zookeeper-client
        image: confluentinc/cp-zookeeper:6.1.0
        command:
          - sh
          - -c
          - "exec tail -f /dev/null"

2. Log into the Pod

  kubectl exec -it zookeeper-client -- /bin/bash

3. Use zookeeper-shell to connect in the zookeeper-client Pod:

  zookeeper-shell local-confluent-kafka-cp-zookeeper:2181

4. Explore with zookeeper commands, for example:

  # Gives the list of active brokers
  ls /brokers/ids

  # Gives the list of topics
  ls /brokers/topics

  # Gives more detailed information of the broker id '0'
  get /brokers/ids/0## ------------------------------------------------------
## Kafka
## ------------------------------------------------------
To connect from a client pod:

1. Deploy a kafka client pod with configuration:

    apiVersion: v1
    kind: Pod
    metadata:
      name: kafka-client
      namespace: default
    spec:
      containers:
      - name: kafka-client
        image: confluentinc/cp-enterprise-kafka:6.1.0
        command:
          - sh
          - -c
          - "exec tail -f /dev/null"

2. Log into the Pod

  kubectl exec -it kafka-client -- /bin/bash

3. Explore with kafka commands:

  # Create the topic
  kafka-topics --zookeeper local-confluent-kafka-cp-zookeeper-headless:2181 --topic local-confluent-kafka-topic --create --partitions 1 --replication-factor 1 --if-not-exists

  # Create a message
  MESSAGE="`date -u`"

  # Produce a test message to the topic
  echo "$MESSAGE" | kafka-console-producer --broker-list local-confluent-kafka-cp-kafka-headless:9092 --topic local-confluent-kafka-topic

  # Consume a test message from the topic
  kafka-console-consumer --bootstrap-server local-confluent-kafka-cp-kafka-headless:9092 --topic local-confluent-kafka-topic --from-beginning --timeout-ms 2000 --max-messages 1 | grep "$MESSAGE"
